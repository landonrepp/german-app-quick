# Local overrides for translation job using Ollama (OpenAI-compatible)

# Point to Ollama's OpenAI-compatible endpoint
OPENAI_BASE_URL=http://localhost:11434/v1

# Dummy key (Ollama ignores but header is required by our client)
OPENAI_API_KEY=ollama

# Llama 3.2 model tag available in your Ollama install
# Examples: llama3.2, llama3.2:latest, llama3.2:3b
OPENAI_MODEL=llama3.2

# Poll every 5s; autostart the background worker in dev
TRANSLATION_POLL_MS=5000
TRANSLATION_JOB_AUTOSTART=1

# Number of pending cards to translate per batch request
TRANSLATION_BATCH_SIZE=10

# In dev, synthesize translations if the model response is invalid
TRANSLATION_DEV_FALLBACK=1
